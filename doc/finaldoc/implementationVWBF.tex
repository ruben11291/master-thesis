
\section{Implementation in Virtual Wall and BonFIRE}




In this chapter, the implementation is introduced indicating the testbeds involved in it and the required steps for the implementation.

Fistly, the implementation of the\ Space System
Simulator in \vw is depicted. The designed topology and the new
modified topology (different to the designed one) are depicted because of the handicaps of
the hardware during the implementation. Then, nodes reservation is
explained and detailed. Finally, the scripts included in each type of
node are described before the presentation of the execution.

The next section is dedicated to the implementation of the software
developed in the \bonfire testbed. Nodes reservation is firstly
depicted. Architecture and setup are also explained. And again, the
scripts for each node setup are included before the description of the
execution.

Finally, the integration between \vw and \bonfire is described.

% Section 6 is devoted\ to\ describe the\ demonstration\ of the\ GEO-Cloud
% experiment prepared for the European Commission in June 2014.


% \bigskip

% Finally, section 7 provides\ the main\ conclusions.


\subsection{Implementation in Virtual Wall}

In \vw the \sss was implemented. It is constituted of the
following modules:
\begin{itemize}
\item The \emph{Satellite System Simulator}
\item The \emph{Ground Station System Simulator}

The topology network designed is depicted in Figure~\ref{fig:impl-topology-vw}.

\begin{figure}[!h]
\begin{center}
\includegraphics[width=0.6\textwidth]{implementationVWBF/gs-sat.png}

\caption{Topology Network in \vw}
\label{fig:impl-topology-vw}
\end{center}
\end{figure}



The previous topology network involves Sat nodes to have 12 connections with the GS nodes; and GS nodes 17 connections with Sat nodes plus one connection with the BonFIRE cloud.

The nodes in \vw have a limitation of 5 physical connections. To deploy the previous
topology we adapted the \sss software to establish those connections by software. This was
done by making the \satss flexible to connect with any ground station from GS1 to GS12. Then the \satss can be multiplied and only connect to it the number of GS nodes desired. 

The solution was to multiply the \satss by three and connect 4 ground stations to each \satss. This ensures the same performance and dynamics of the previous topology network described in Figure~\ref{fig:impl-topology-vw}, and the only thing it changes is the software.

The \sss implemented in \vw is depicted in Figure~\ref{fig:impl-nodes-vw}.

\begin{figure}[!h]
\begin{center}
\includegraphics[width=0.6\textwidth]{implementationVWBF/nodes-vw.png}

\caption{Topology Network in \vw}
\label{fig:impl-nodes-vw}
\end{center}
\end{figure}



\subsubsection{Nodes Reservation and Setup}


The \sss is then constituted by 15 ``Generic nodes'' in \vw 1 (The \vw
testbed is composed by two sets of machines, \vw 1 and \vw 2). The configuration of the experiment makes the provisioning of ``any available node'',
which is more flexible in case a node is being used in other experiment (see Figure~\ref{fig:creating-node-jfed}). The links between SS \emph{(Satellite Simulators)} and GS \emph{(Ground Stations Simulators)} nodes
are \emph{TCP}. The definition of the dependencies and the commands that will be installed at
setup is defined in \emph{JFed} using a \emph{RSPEC} specification. This specification includes some
bash commands or instructions that will execute after reservation automatically.


\begin{figure}[!h]
\begin{center}
\includegraphics[width=0.6\textwidth]{implementationVWBF/creating-node-jfed.png}

\caption{Configuration of \vw nodes}
\label{fig:creating-node-jfed}
\end{center}
\end{figure}


\paragraph{Satellite Simulator Nodes Setup}~\\

The configuration of the nodes is done by using \emph{JFed RSPEC Experiment}. The
setup steps are the following:
\begin{itemize}
\item To configurate a gateway to obtain connectivity with Internet for installing the
  needed libraries.
\item To update the system.
\item Once the update is finished, dependencies can be installed.
\item As the simulators require a connection with a database, the \emph{MySQL} library is
  also required. 
\item Source is downloaded from Google Drive where is located.
\end{itemize}

The script that perform the above is showed in Listing~\emph{code:impl-rspec-sat-sim}.

\begin{listing}[
  float=h!,
  caption  = {RSPEC specification for \emph{Satellite Simulators}},
  label    = code:impl-rspec-sat-sim,
  style=customc]

<execute shell="sh" command="sudo route del default gw 10.2.15.254"/>
<execute shell="sh" command="sudo route add default gw 10.2.15.253"/>
<execute shell="sh" command="sudo apt-get update"/>
<execute shell="sh" command="sudo apt-get install python python-mysqldb -y"/>

<execute shell="sh" command="sudo wget --no-check-certificate <<google_drive_host_address>> -O
/users/jbecedas/push_dbIP.sh"/>
<execute shell="sh" command="sudo bash /users/jbecedas/push_dbIP.sh 129.215.175.147"/>
<execute shell="sh" command="sudo wget --no-check-certificate
<<google_drive_host_address>> -O /users/jbecedas/satellite.py"/>
\end{listing}


Where <<google_drive_host_address>> is the address of the Google Drive URI in which the scripts are located.

The \emph{Database} is located in \bonfire and it has an \emph{IP address} that can change. In order to
obtain that \emph{IP address} and include it in the \emph{Satellite Simulator}, a simple script to
acquire the \emph{IP address} of the database was developed ``push_dbIP.sh''.
Listing~\ref{code:impl-script-ipdb} contains the script.

\begin{listing}[
  float=h!,
  caption  = {Bash script to write the Database's\emph{IP address} on a file},
  label    = code:impl-script-ipdb,
  style=customc]

#!/bin/bash

ip=$1

touch /users/jbecedas/ipdb
echo $ip > /users/jbecedas/ipdb
\end{listing}

The execution of the push_dbIP.sh script acquires the IP of the database and includes it in the file ipdb, created by “push_dbIP.sh”:


Now, the node is perfectly configured to proceed with the installation of the Satellite Simulator. The software of the simulator has been archived too in Google Drive. With the following command the software is acquired:

It can now be executed in the node.


\subsubsection{Ground Station Simulator Nodes Setup}


The \emph{Ground Station Simulators} software is developed under Python. To install the libraries the nodes need connectivity with the Internet. For that purpose a gateway has to be configured:

<execute shell="sh" command="sudo route del default gw 10.2.15.254"/> <execute shell="sh" command="sudo route add default gw 10.2.15.253"/>
As occurred with the SS nodes, the update and the installation of Python and MySQL are required:

<execute shell="sh" command="sudo apt-get update"/>  <execute shell="sh" command="sudo apt-get install python python-mysqldb -y"/>

The \emph{IP address} of the database has to be included in the node:

<execute shell="sh" command="sudo wget --no-check-certificate google_drive_host_address -O /users/jbecedas/push_dbIP.sh"/> <execute shell="sh" command="sudo bash /users/jbecedas/push_dbIP.sh 129.215.175.147"/>

The software of the \emph{Ground Stations Simulator} is also located in Google Drive:

<execute shell="sh" command="sudo wget --no-check-certificate google_drive_host_address  -O /users/jbecedas/groundstation.py"/>

The GS nodes are required to open an \emph{FTP} to be accessed from the \emph{Orchestrator} in \bonfire. The \emph{FTP} is configured by executing the “install_ftp.sh” file. This file has the following code:

#!/bin/bash

sudo apt-get update
sudo apt-get install mysql-client ftp ftplib3 vsftpd -y
sudo sed -i "s/listen=YES/listen=NO/" /etc/vsftpd.conf
sudo sed -i "s/#listen_ipv6=NO/listen_ipv6=YES/" /etc/vsftpd.conf
sudo sed -i "s/#listen_ipv6=YES/listen_ipv6=YES/" /etc/vsftpd.conf
sudo sed -i "s/anonymous_enable=YES/anonymous_enable=NO/" /etc/vsftpd.conf
sudo sed -i "s/#local_enable=NO/local_enable=YES/" /etc/vsftpd.conf
sudo sed -i "s/#local_enable=YES/local_enable=YES/" /etc/vsftpd.conf
sudo sed -i "s/#write_enable=NO/write_enable=YES/" /etc/vsftpd.conf
sudo sed -i "s/#write_enable=YES/write_enable=YES/" /etc/vsftpd.conf
sudo sed -i "s/#local_umask/local_umask/" /etc/vsftpd.conf
sudo sed -i "s/#chroot_list_file/chroot_list_file/" /etc/vsftpd.conf
sudo mkdir -p /home/ftp/deimos
sudo mkdir /home/deimos
sudo useradd -d /home/deimos -g ftp  deimos
sudo chmod 777 -R /home
sudo touch /etc/vsftpd.chroot_list
sudo su
echo "deimos:deimos"|chpasswd
echo "deimos" >> /etc/vsftpd.chroot_list
sudo service vsftpd restart

It is executed as follows:

<execute shell="sh" command="sudo bash /users/jbecedas/install_ftp.sh"/>

Through the FTP connection the raw data will be transferred from the GS nodes to the BonFIRE cloud. The raw data is located in Google Drive too.

<execute shell="sh" command="sudo wget --no-check-certificate google_drive_host_address -O /tmp/original.bin "/> 


The execution of the Satellite Simulators and the Ground Station Simulators is described
in Section~\ref{par:sat-simulator-execution} and Section~\ref{par:sss-ground-execution}. 

% Local Variables:
%   coding: utf-8
%   fill-column: 90
%   mode: flyspell
%   ispell-local-dictionary: "american"
%   mode: latex
%   TeX-master: "main"
% End:
